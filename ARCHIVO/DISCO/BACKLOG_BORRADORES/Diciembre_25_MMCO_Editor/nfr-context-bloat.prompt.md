# Prompt: Negociaci√≥n NFR - Context Bloat en .github/

> **Plugin**: Scrum  
> **Comando**: `@scrum nfr-negociacion`  
> **Fase**: Planificaci√≥n (Non-Functional Requirements)
> **Fuente**: `ARCHIVO/DISCO/Diciembre_25_MMCO_Editor/critica-prompting-pathykar.md`

---

## Contexto de la Negociaci√≥n

**Situaci√≥n**: El SM ha identificado un anti-patr√≥n cr√≠tico en la ingenier√≠a de prompting del Scriptorium tras analizar `Pathykar.inner.md`. El an√°lisis revela que el 92% de los tokens (117K de 128K) se consumen en contexto, dejando solo 8% para respuestas.

**Tensi√≥n**: El SM quiere dedicar tiempo al redise√±o de `.github/` para paliar el problema. El PO no ver√° nuevas features durante este trabajo. Negociaci√≥n t√≠pica de NFR (Non-Functional Requirements).

---

## Conversaci√≥n PO-SM-T√©cnicos

### Apertura

**SM**: Tenemos un problema estructural que necesito escalar antes de planificar el siguiente sprint. He analizado el documento `Pathykar.inner.md` ‚Äîun dump de 8,849 l√≠neas de una request a Copilot‚Äî y los n√∫meros son alarmantes.

**Pathykar (PO)**: Dame los n√∫meros concretos. ¬øQu√© tan malo es?

**SM**: 
| M√©trica | Valor | Problema |
|---------|-------|----------|
| Tokens de prompt | 117,877 | 92% del l√≠mite de 128K |
| Tokens cacheados | 115,430 | 98% redundante |
| Attachments | 23 | Mayor√≠a innecesarios para la tarea |
| **Ratio se√±al/ruido** | **~3%** | Solo ~250 l√≠neas de 8,849 eran la tarea real |

**Pathykar (PO)**: Espera, ¬øme est√°s diciendo que el 97% del contexto que enviamos al modelo es ruido?

**SM**: Exactamente. Y peor: el sistema auto-inyecta archivos por patrones glob sin filtrar por relevancia. El usuario controla solo el 3% del contexto; el 97% lo decide el sistema autom√°ticamente.

---

### Fase 1: Entender el problema

**Ox** (entrando a la conversaci√≥n): Como or√°culo del sistema, puedo confirmar el diagn√≥stico. El problema est√° en c√≥mo hemos configurado `.github/instructions/`. Cada archivo tiene un `applyTo` con patrones glob demasiado amplios:

```yaml
# Ejemplo actual (problem√°tico)
applyTo: "ARCHIVO/DISCO/**/*.md"
```

Esto significa que cualquier conversaci√≥n que toque cualquier archivo en DISCO incluye TODAS las instrucciones. El sistema de la escalera cr√≠tica se activa aunque no sea relevante.

**Pathykar (PO)**: Pero Ox, ¬øno era la idea que el sistema fuera contextualmente rico? Quer√≠amos que el modelo "supiera" sobre el Scriptorium completo.

**Ox**: S√≠, pero hay una diferencia entre "conocimiento disponible" y "conocimiento inyectado siempre". El diagn√≥stico de banderas revela:

| Bandera | Test | Veredicto |
|---------|------|-----------|
| üîµ Blueflag | ¬øAttachments necesarios? | ‚ùå Solo 26% eran relevantes |
| ‚ö´ Blackflag | ¬øQui√©n controla el contexto? | ‚ö†Ô∏è Usuario perdi√≥ control |
| üî¥ Redflag | ¬øEs sostenible a escala? | ‚ùå Opera al l√≠mite de recursos |
| üü° Yellowflag | ¬øSeparaci√≥n metadatos/contenido? | ‚ùå Blob monol√≠tico |
| üü† Orangeflag | ¬øAuditorio claro? | ‚ùå No sirve a modelo ni humano |

---

### Fase 2: El dilema del PO

**Pathykar (PO)**: Entiendo la severidad t√©cnica. Pero necesito que entiendas mi posici√≥n: tenemos el roadmap de la √âpoca 2 (Extensi√≥n) con √©picas pendientes:

1. Plugins transversales (TypedPrompting, N8N, Blockly)
2. Subm√≥dulos especializados
3. Los 12 cap√≠tulos de Fundaci√≥n

Si paramos para "redise√±ar el sistema de prompting", ¬øcu√°nto tiempo perdemos?

**SM**: No es "perder tiempo", es inversi√≥n en sostenibilidad. Pero entiendo tu punto. D√©jame traer a Aleph para que nos d√© la perspectiva DevOps.

---

### Fase 3: Perspectiva DevOps

**Aleph**: Desde DevOps, veo tres niveles de riesgo si no actuamos:

#### Riesgo Inmediato (ya est√° pasando)
```
- Respuestas truncadas: Solo quedan 10K tokens para output
- Latencia degradada: 16 segundos por request (deber√≠a ser <5s)
- Caching in√∫til: 98% cacheado significa acumulaci√≥n t√≥xica
```

#### Riesgo a Corto Plazo (1-2 sprints)
```
- Conversaciones largas imposibles: No hay espacio para evoluci√≥n
- Tareas complejas fallar√°n: El modelo no puede razonar bien
- Frustraci√≥n de operador: El sistema no responde como esperado
```

#### Riesgo a Largo Plazo (√âpoca 3)
```
- Los 12 cap√≠tulos necesitan contexto extenso
- Pipeline de noticias requiere iteraci√≥n
- Teatro Interactivo con memoria ‚Üí imposible con context bloat
```

**Pathykar (PO)**: Entonces no es "paramos para features lindas de infraestructura". Es "paramos ahora o el sistema colapsa durante √âpoca 3".

**Aleph**: Exacto. Y hay algo peor: cada sprint que sigamos sin arreglar esto, acumulamos m√°s instructions, m√°s patrones glob, m√°s auto-inyecci√≥n. El problema escala.

---

### Fase 4: Plan de Paliaci√≥n

**SM**: Propongo un plan de tres niveles. Podemos hacer el Nivel 1 inmediatamente, Nivel 2 en un sprint dedicado, Nivel 3 como √©pica de √âpoca 2.

#### Nivel 1: Correcciones Inmediatas (1-2 d√≠as, sin sprint dedicado)

| Acci√≥n | Impacto | Effort |
|--------|---------|--------|
| Reducir patrones glob | -50K tokens | 1 pt |
| Eliminar instructions redundantes | -20K tokens | 1 pt |
| Documentar qu√© se auto-inyecta | Visibilidad | 1 pt |

**Cambio espec√≠fico**:
```yaml
# Antes
applyTo: "ARCHIVO/DISCO/**/*.md"

# Despu√©s  
applyTo: "ARCHIVO/DISCO/{carpeta_espec√≠fica}/**/*.md"
```

#### Nivel 2: Refactorizaci√≥n (Sprint dedicado)

| Acci√≥n | Impacto | Effort |
|--------|---------|--------|
| Crear instrucciones por tipo de tarea | Contexto enfocado | 3 pts |
| Usar `isSummarized` para agentes | -30K tokens | 2 pts |
| Implementar presets de contexto | Control recuperado | 5 pts |

#### Nivel 3: Arquitectura (√âpica de √âpoca 2)

| Acci√≥n | Impacto | Effort |
|--------|---------|--------|
| Separar logs de documentos de trabajo | Claridad | 5 pts |
| Sistema de filtrado de relevancia | -60% tokens | 13 pts |
| M√©tricas de salud de contexto | Monitoreo | 5 pts |

---

### Fase 5: Negociaci√≥n Final

**Pathykar (PO)**: Veo el plan. Mi propuesta:

1. **Nivel 1 lo hacemos AHORA** como parte del sprint actual. Son 3 puntos, no bloquean nada.
2. **Nivel 2 NO requiere sprint dedicado completo**. ¬øPodemos hibridar? 50% features, 50% deuda t√©cnica en un sprint.
3. **Nivel 3** lo a√±adimos como √©pica formal de √âpoca 2 con visibilidad en backlog.

**SM**: Acepto el h√≠brido del Nivel 2, pero con condici√≥n: necesito m√©tricas pre/post para demostrar el impacto. Si despu√©s del Nivel 1 no bajamos a menos de 60K tokens por request promedio, escalamos a Nivel 2 completo.

**Ox**: Puedo instrumentar eso. Crear√© un script de diagn√≥stico que mida:
- Tokens promedio por request
- Ratio de attachments relevantes vs. inyectados
- Tiempo de respuesta

**Aleph**: Desde DevOps, me comprometo a que el Nivel 1 est√© listo antes del siguiente standup. Es refactorizaci√≥n de YAML, no c√≥digo.

---

### Cierre

**Pathykar (PO)**: Aprobado. Resumen ejecutivo:

> **NFR Sprint: Context Bloat Mitigation**
> 
> - **Objetivo**: Reducir tokens de prompt de 117K a <50K
> - **Nivel 1**: Inmediato (hoy/ma√±ana) - 3 pts
> - **Nivel 2**: H√≠brido en pr√≥ximo sprint - 10 pts
> - **Nivel 3**: √âpica formal en backlog √âpoca 2 - 23 pts
> - **M√©trica de √©xito**: Ratio se√±al/ruido >50% (actual: 3%)
> - **Responsables**: 
>   - Aleph (YAML de instructions)
>   - Ox (m√©tricas de diagn√≥stico)
>   - SM (seguimiento y validaci√≥n)

**SM**: Documentando. Generar√© el backlog detallado cuando confirmes.

---

## Archivos Afectados (Nivel 1)

Los siguientes archivos de `.github/instructions/` requieren revisi√≥n de patrones glob:

| Archivo | Patr√≥n Actual | Patr√≥n Propuesto |
|---------|---------------|------------------|
| `periodico.instructions.md` | `ARCHIVO/DISCO/**/*.md` | `ARCHIVO/DISCO/**/conversacion*.md` |
| `submodulo-integracion.instructions.md` | `**/*` | `BlockchainComPort/**/*` |
| `foro-scraper.instructions.md` | `ARCHIVO/**/*.md` | `ARCHIVO/NOTICIAS/**/*.md` |
| `scrum-protocol.instructions.md` | `ARCHIVO/DISCO/**/*.md` | `ARCHIVO/DISCO/**/backlog*.md` |

## M√©tricas Target

| M√©trica | Actual | Post-Nivel1 | Post-Nivel2 | Target Final |
|---------|--------|-------------|-------------|--------------|
| Tokens por request | 117K | <60K | <40K | <30K |
| Attachments relevantes | 26% | >50% | >70% | >80% |
| Ratio se√±al/ruido | 3% | >20% | >40% | >50% |
| Tiempo de respuesta | 16s | <10s | <7s | <5s |

---

## Siguiente Paso

`@scrum borrador` para generar el backlog detallado de la √©pica "Context Bloat Mitigation".

